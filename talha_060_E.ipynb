{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "#have used sklearn and ktrain modules, they need installation\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.utils as ku \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "device = torch.device(\"cuda\")\n",
    "#used train.csv and test.csv and dev.csv file from codalab\n",
    "trainingfile = 'train.csv'\n",
    "testingfile = 'test.csv'\n",
    "validationfile = 'dev.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainingdata_S = pd.read_csv(trainingfile)\n",
    "testingdata_S = pd.read_csv(testingfile)\n",
    "validationdata_S = pd.read_csv(validationfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns\n",
    "drop_labels = ['Confusing Reason1' \t,'Confusing Reason2', \t'Right Reason2']\n",
    "trainingdata_S.drop(drop_labels, axis = 1, inplace= True)\n",
    "testingdata_S.drop(drop_labels, axis = 1, inplace= True)\n",
    "validationdata_S.drop(drop_labels, axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_statement= []\n",
    "incorrect_statement=[]\n",
    "right_reason1= []\n",
    "right_reason2 = []\n",
    "\n",
    "for i in range(len(trainingdata_S['Correct Statement'])):\n",
    "  correct_statement.append([trainingdata_S.iloc[i,0], 1])\n",
    "  incorrect_statement.append([trainingdata_S.iloc[i,1], 0])\n",
    "  right_reason1.append([trainingdata_S.iloc[i,2], 1])\n",
    "  right_reason2.append([trainingdata_S.iloc[i,3], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = correct_statement + incorrect_statement + right_reason1 + right_reason2\n",
    "random.shuffle(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_statement= []\n",
    "incorrect_statement=[]\n",
    "right_reason1= []\n",
    "right_reason2 = []\n",
    "\n",
    "for i in range(len(testingdata_S['Correct Statement'])):\n",
    "  correct_statement.append([testingdata_S.iloc[i,0], 1])\n",
    "  incorrect_statement.append([testingdata_S.iloc[i,1], 0])\n",
    "  right_reason1.append([testingdata_S.iloc[i,2], 1])\n",
    "  right_reason2.append([testingdata_S.iloc[i,3], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist = correct_statement + incorrect_statement + right_reason1 + right_reason2\n",
    "random.shuffle(testlist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_statement= []\n",
    "incorrect_statement=[]\n",
    "right_reason1= []\n",
    "right_reason2 = []\n",
    "\n",
    "for i in range(len(validationdata_S['Correct Statement'])):\n",
    "  correct_statement.append([validationdata_S.iloc[i,0], 1])\n",
    "  incorrect_statement.append([validationdata_S.iloc[i,1], 0])\n",
    "  right_reason1.append([validationdata_S.iloc[i,2], 1])\n",
    "  right_reason2.append([validationdata_S.iloc[i,3], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationlist = correct_statement + incorrect_statement + right_reason1 + right_reason2\n",
    "random.shuffle(validationlist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnlabels = ['Sentence', 'Values']\n",
    "traindata_df = pd.DataFrame(datalist, columns = columnlabels)\n",
    "testdata_df = pd.DataFrame(testlist, columns = columnlabels)\n",
    "devdata_df = pd.DataFrame(validationlist, columns = columnlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you need to be asleep to stay up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I drank some cactus from a thermos.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medication is not sold at gas stations.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audiences perform during a play.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new batteries provide power to make the flashl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Values\n",
       "0                   you need to be asleep to stay up       0\n",
       "1                I drank some cactus from a thermos.       0\n",
       "2            Medication is not sold at gas stations.       1\n",
       "3                   Audiences perform during a play.       0\n",
       "4  new batteries provide power to make the flashl...       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_t, Y_t) , (X_T, Y_T), preprocess = text.texts_from_df(train_df= traindata_df, \n",
    "text_column= 'Sentence', \n",
    "label_columns= 'Values',\n",
    "val_df = devdata_df,\n",
    "maxlen = 400,\n",
    "preprocess_mode = 'bert')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 400\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier(name='bert',train_data = (X,Y),preproc = preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ktrain.get_learner(model = model,train_data = (X,Y),val_data = (X_T, Y_T),batch_size = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_onecycle(lr = 2e-2, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
